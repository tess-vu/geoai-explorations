{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p2JZt1GL5D6W"
      },
      "source": [
        "# Introduction to CUDA and PyCUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxnVi8UHrAmE"
      },
      "source": [
        "Install the required module `pycuda`, the `rasterio` is for geotiff file operation. We will use it for raster data operations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUxfgZM8rMeA"
      },
      "source": [
        "#### Import the required `pycuda` libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FA_YN7HlGRP5"
      },
      "outputs": [],
      "source": [
        "import pycuda.autoinit\n",
        "import pycuda.driver as cuda\n",
        "import numpy as np\n",
        "from pycuda.compiler import SourceModule"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-Pd0E4W42ws2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Tess\\AppData\\Local\\Temp\\ipykernel_82428\\2039429436.py:2: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "kernel.cu\n",
            "\n",
            "  mod = SourceModule(\"\"\"\n"
          ]
        }
      ],
      "source": [
        "# Define CUDA kernel\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void add_vectors(float *a, float *b, float *c, int N) {\n",
        "    int idx = threadIdx.x + blockIdx.x * blockDim.x;\n",
        "\n",
        "    if (idx < N) {\n",
        "        c[idx] = a[idx] + b[idx];\n",
        "    }\n",
        "}\n",
        "\"\"\")\n",
        "\n",
        "# Get the kernel function\n",
        "add_vectors = mod.get_function(\"add_vectors\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zDSdMm7T20nO"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr_2QYV9oSOA",
        "outputId": "2b33df50-b0f6-4d1d-ada7-1ba69cb9e116"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([ 0.18346167,  0.9063867 , -0.7365927 , ...,  0.1067035 ,\n",
              "        -1.9502953 , -0.5399432 ], shape=(1024,), dtype=float32),\n",
              " array([-1.0885758 ,  0.11922219, -0.78583676, ...,  0.93014514,\n",
              "         0.0380047 ,  0.07656984], shape=(1024,), dtype=float32),\n",
              " array([0., 0., 0., ..., 0., 0., 0.], shape=(1024,), dtype=float32))"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create input data\n",
        "N = 1024\n",
        "a = np.random.randn(N).astype(np.float32)\n",
        "b = np.random.randn(N).astype(np.float32)\n",
        "c = np.empty_like(a)\n",
        "a, b, c"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "6Bkueg4VovJ_"
      },
      "outputs": [],
      "source": [
        "# Allocate GPU memory\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "b_gpu = cuda.mem_alloc(b.nbytes)\n",
        "c_gpu = cuda.mem_alloc(c.nbytes)\n",
        "\n",
        "# Copy data from host (CPU) to device (GPU)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "cuda.memcpy_htod(b_gpu, b)\n",
        "\n",
        "\n",
        "# Define grid and block size\n",
        "block_size = 256\n",
        "grid_size = (N + block_size - 1) // block_size\n",
        "\n",
        "# Launch the kernel\n",
        "add_vectors(a_gpu, b_gpu, c_gpu, np.int32(N), block=(block_size, 1, 1), grid=(grid_size, 1, 1))\n",
        "\n",
        "# Copy result back from device (GPU) to host (CPU)\n",
        "cuda.memcpy_dtoh(c, c_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2t2QNOg5pHUj",
        "outputId": "58aaf1a0-c406-44e9-d68c-0f35d040a952"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<pycuda._driver.DeviceAllocation at 0x14b208cdea0>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c_gpu"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXtNe8sTpNH5",
        "outputId": "49524e8a-160d-4338-f621-407cb6db68ed"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1024,)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "c.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0y3wDg1WkWPs",
        "outputId": "c08d0afb-43f6-4fd2-a874-52a03c9963ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First 5 results:\n",
            "GPU result: [-0.9051142   1.0256089  -1.5224295  -0.8016787  -0.13093054]\n",
            "Expected: [-0.9051142   1.0256089  -1.5224295  -0.8016787  -0.13093054]\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Verify the result\n",
        "print(\"First 5 results:\")\n",
        "print(\"GPU result:\", c[:5])\n",
        "print(\"Expected:\", (a + b)[:5])\n",
        "\n",
        "# Free GPU memory (optional, PyCUDA auto-manages it)\n",
        "a_gpu.free()\n",
        "b_gpu.free()\n",
        "c_gpu.free()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJBVoR8ANgx5"
      },
      "source": [
        "# Exercises\n",
        "\n",
        "1. Write a cuda kernel to find the elementwise square of a matrix\n",
        "2. Write a cuda kernel to multiply three matrices:"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "geoai",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
